{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mnist_train = pd.read_csv('MNIST_data/train.csv')\n",
    "mnist_test = pd.read_csv('MNIST_data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 784) (30000, 1) (12000, 784) (12000, 1) (28000, 784)\n"
     ]
    }
   ],
   "source": [
    "y_train = mnist_train[['label']][:30000]\n",
    "x_train = mnist_train[['pixel' + str(idx) for idx in range(784)]][:30000]\n",
    "\n",
    "y_dev = mnist_train[['label']][30000:42000]\n",
    "x_dev = mnist_train[['pixel' + str(idx) for idx in range(784)]][30000:42000]\n",
    "\n",
    "x_test = mnist_test[['pixel' + str(idx) for idx in range(784)]]\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_dev = scaler.transform(x_dev)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "\n",
    "print x_train.shape, y_train.shape, x_dev.shape, y_dev.shape, x_test.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EPSILON = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def DNN_BN(x, weights, beta, scale, activation_function = None):\n",
    "    wx = tf.matmul(x, weights)\n",
    "    mean, var = tf.nn.moments(wx, [0])\n",
    "    bn = tf.nn.batch_normalization(wx, mean, var, beta, scale, EPSILON)\n",
    "    if not activation_function:\n",
    "        return bn\n",
    "    else:\n",
    "        return activation_function(bn)\n",
    "    \n",
    "def DNN(x, weights, biases, activation_function = None):\n",
    "    wx = tf.matmul(x, weights)\n",
    "    score = wx + biases\n",
    "    if not activation_function:\n",
    "        return score\n",
    "    else:\n",
    "        return activation_function(score)\n",
    "    \n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "def scale_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "      return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "def max_pool_2x2(x):\n",
    "      return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    \n",
    "def get_center_loss(features, labels):\n",
    "    with tf.variable_scope('center', reuse=True):\n",
    "        centers = tf.get_variable('centers')\n",
    "    \n",
    "    len_features = features.get_shape()[1]\n",
    "    labels = tf.reshape(labels, [-1])\n",
    "\n",
    "    centers_batch = tf.gather(centers, labels)\n",
    "    # 计算center loss的数值\n",
    "    loss = tf.reduce_sum((features - centers_batch) ** 2, [1])\n",
    " \n",
    "    return loss\n",
    "\n",
    "def update_centers(features, labels, alpha):\n",
    "    with tf.variable_scope('center', reuse=True):\n",
    "        centers = tf.get_variable('centers')\n",
    "    \n",
    "    labels = tf.reshape(labels, [-1])\n",
    "    centers_batch = tf.gather(centers, labels)\n",
    "    \n",
    "    diff = centers_batch - features\n",
    "\n",
    "        # 获取一个batch中同一样本出现的次数，这里需要理解论文中的更新公式\n",
    "    unique_label, unique_idx, unique_count = tf.unique_with_counts(labels)\n",
    "    appear_times = tf.gather(unique_count, unique_idx)\n",
    "    appear_times = tf.reshape(appear_times, [-1, 1])\n",
    "\n",
    "    diff = diff / tf.cast((1 + appear_times), tf.float32)\n",
    "    diff = alpha * diff\n",
    "        # 更新中心\n",
    "    centers = tf.scatter_sub(centers,labels, diff)\n",
    "    \n",
    "    return centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS, Softmax_loss, Center_loss [14661.275, array([ 20.77036095,  28.87823105,   5.987041  , ...,   5.14118719,\n",
      "         2.83091307,  20.5743351 ], dtype=float32), array([  8280.03222656,  11889.84179688,   4655.91943359, ...,\n",
      "         8676.53710938,  10928.06738281,  12933.61523438], dtype=float32)]\n",
      "ACC@TRAIN: 0.152067\n",
      "ACC@DEV: 0.150583\n",
      "LOSS, Softmax_loss, Center_loss [1674.7488, array([  6.70772934,  13.04281139,   2.08791828, ...,   2.29346609,\n",
      "         4.76612854,   7.96797609], dtype=float32), array([ 520.92028809,  555.72418213,  153.61328125, ...,  770.92468262,\n",
      "        887.10717773,  931.63354492], dtype=float32)]\n",
      "ACC@TRAIN: 0.157333\n",
      "ACC@DEV: 0.160667\n",
      "LOSS, Softmax_loss, Center_loss [839.83411, array([ 4.04769897,  7.35984325,  1.99517202, ...,  1.65925431,\n",
      "        3.38484025,  4.02865982], dtype=float32), array([ 258.75866699,  282.50292969,   81.88085175, ...,  345.340271  ,\n",
      "        425.21444702,  441.53942871], dtype=float32)]\n",
      "ACC@TRAIN: 0.1467\n",
      "ACC@DEV: 0.148833\n",
      "LOSS, Softmax_loss, Center_loss [490.89554, array([ 3.78952909,  4.06056261,  1.84711671, ...,  1.84946346,\n",
      "        3.11742234,  2.37636542], dtype=float32), array([ 153.73274231,  160.05535889,   51.00437164, ...,  183.49337769,\n",
      "        233.81852722,  236.92304993], dtype=float32)]\n",
      "ACC@TRAIN: 0.1405\n",
      "ACC@DEV: 0.14325\n",
      "LOSS, Softmax_loss, Center_loss [303.56357, array([ 3.69176817,  2.28945208,  1.66727006, ...,  2.45960474,\n",
      "        2.83887744,  2.05154085], dtype=float32), array([  98.30134583,   98.81141663,   31.13149261, ...,   96.95912933,\n",
      "        144.78961182,  132.91563416], dtype=float32)]\n",
      "ACC@TRAIN: 0.132633\n",
      "ACC@DEV: 0.136083\n",
      "LOSS, Softmax_loss, Center_loss [192.31329, array([ 3.18623877,  1.68104351,  1.74605882, ...,  2.43642831,\n",
      "        2.37639141,  2.00658655], dtype=float32), array([ 57.41234207,  63.14451599,  20.28462982, ...,  52.22312164,\n",
      "        94.98255157,  81.58531189], dtype=float32)]\n",
      "ACC@TRAIN: 0.118933\n",
      "ACC@DEV: 0.124417\n",
      "LOSS, Softmax_loss, Center_loss [122.94115, array([ 2.52243614,  1.55318785,  1.65272474, ...,  2.25652027,\n",
      "        2.71439338,  1.84173322], dtype=float32), array([ 33.67969513,  35.99014664,  10.25572681, ...,  29.86258316,\n",
      "        56.01817322,  45.74469757], dtype=float32)]\n",
      "ACC@TRAIN: 0.101067\n",
      "ACC@DEV: 0.105417\n",
      "LOSS, Softmax_loss, Center_loss [79.177765, array([ 1.95885777,  2.04380131,  1.80321872, ...,  2.4531281 ,\n",
      "        2.68667316,  2.17196751], dtype=float32), array([ 17.76834106,  18.46720886,   5.56966829, ...,  19.39495087,\n",
      "        32.81892776,  19.75457001], dtype=float32)]\n",
      "ACC@TRAIN: 0.0697333\n",
      "ACC@DEV: 0.074\n",
      "LOSS, Softmax_loss, Center_loss [52.874641, array([ 1.94904602,  2.60097647,  1.9948976 , ...,  2.71013832,\n",
      "        2.31748581,  2.81833887], dtype=float32), array([ 10.14742947,  10.68436527,   3.16263628, ...,  13.23696518,\n",
      "        18.7151165 ,   9.86598396], dtype=float32)]\n",
      "ACC@TRAIN: 0.0739333\n",
      "ACC@DEV: 0.0768333\n",
      "LOSS, Softmax_loss, Center_loss [36.692684, array([ 1.87607753,  2.93411279,  1.82449174, ...,  3.0445435 ,\n",
      "        2.23333263,  3.1470902 ], dtype=float32), array([  8.461833  ,   6.81667519,   0.98525351, ...,   7.94391298,\n",
      "        10.62164497,   3.49952698], dtype=float32)]\n",
      "ACC@TRAIN: 0.0871667\n",
      "ACC@DEV: 0.0895\n",
      "LOSS, Softmax_loss, Center_loss [26.224075, array([ 2.02889204,  2.71098447,  1.90217924, ...,  2.92873955,\n",
      "        2.25722361,  3.10127831], dtype=float32), array([ 7.34266376,  5.08627892,  0.75184608, ...,  5.79339695,\n",
      "        6.59288311,  1.37757587], dtype=float32)]\n",
      "ACC@TRAIN: 0.0882333\n",
      "ACC@DEV: 0.0901667\n",
      "LOSS, Softmax_loss, Center_loss [18.913563, array([ 2.22310567,  2.61933732,  2.21143818, ...,  2.96208048,\n",
      "        2.13444018,  2.77122068], dtype=float32), array([ 2.10138321,  3.16476917,  0.36898649, ...,  2.99782968,\n",
      "        3.55555272,  0.38296983], dtype=float32)]\n",
      "ACC@TRAIN: 0.0852333\n",
      "ACC@DEV: 0.08575\n",
      "LOSS, Softmax_loss, Center_loss [13.557633, array([ 2.29977202,  2.5038743 ,  2.29597211, ...,  2.93769503,\n",
      "        2.41802144,  2.66775179], dtype=float32), array([ 0.11950952,  2.13998461,  0.26177004, ...,  1.73108792,\n",
      "        0.26708931,  0.40140447], dtype=float32)]\n",
      "ACC@TRAIN: 0.1001\n",
      "ACC@DEV: 0.101667\n",
      "LOSS, Softmax_loss, Center_loss [11.000704, array([ 2.28410792,  2.45273161,  2.28297949, ...,  2.83951902,\n",
      "        2.38146186,  2.59963989], dtype=float32), array([ 0.15428132,  1.77111602,  0.23191807, ...,  1.94187629,\n",
      "        0.17978428,  0.23304905], dtype=float32)]\n",
      "ACC@TRAIN: 0.1008\n",
      "ACC@DEV: 0.101833\n",
      "LOSS, Softmax_loss, Center_loss [9.2332602, array([ 2.2756474 ,  2.40367842,  2.27561069, ...,  2.74310875,\n",
      "        2.35168743,  2.53174496], dtype=float32), array([ 0.203311  ,  1.64410853,  0.21240278, ...,  2.11976504,\n",
      "        0.12769464,  0.21618524], dtype=float32)]\n",
      "ACC@TRAIN: 0.101333\n",
      "ACC@DEV: 0.102833\n",
      "LOSS, Softmax_loss, Center_loss [7.8059926, array([ 2.27597833,  2.34812546,  2.27545714, ...,  2.63140368,\n",
      "        2.32668352,  2.45436764], dtype=float32), array([ 0.29975083,  1.53258848,  0.21556936, ...,  2.1930716 ,\n",
      "        0.05740632,  0.18258074], dtype=float32)]\n",
      "ACC@TRAIN: 0.103467\n",
      "ACC@DEV: 0.106333\n",
      "LOSS, Softmax_loss, Center_loss [6.2389512, array([ 2.29259682,  2.27655768,  2.29259682, ...,  2.45401073,\n",
      "        2.31298542,  2.34022093], dtype=float32), array([ 0.16321266,  1.16691697,  0.16321266, ...,  1.33116484,\n",
      "        0.06597965,  0.04749426], dtype=float32)]\n",
      "ACC@TRAIN: 0.109833\n",
      "ACC@DEV: 0.113583\n",
      "LOSS, Softmax_loss, Center_loss [5.0908675, array([ 2.29181647,  2.27681136,  2.29181647, ...,  2.30742574,\n",
      "        2.31366301,  2.27681136], dtype=float32), array([ 0.01518869,  0.00360292,  0.01518869, ...,  0.00163435,\n",
      "        0.00045217,  0.00360292], dtype=float32)]\n",
      "ACC@TRAIN: 0.101733\n",
      "ACC@DEV: 0.102917\n",
      "LOSS, Softmax_loss, Center_loss [4.5300741, array([ 2.2909677 ,  2.27718282,  2.2909677 , ...,  2.30741644,\n",
      "        2.31302333,  2.27718282], dtype=float32), array([ 0.01260219,  0.00041167,  0.01260219, ...,  0.00103888,\n",
      "        0.00034494,  0.00041167], dtype=float32)]\n",
      "ACC@TRAIN: 0.102\n",
      "ACC@DEV: 0.10275\n",
      "LOSS, Softmax_loss, Center_loss [4.0957065, array([ 2.29009748,  2.27757096,  2.29009748, ...,  2.30741763,\n",
      "        2.31237936,  2.27757096], dtype=float32), array([ 0.01056263,  0.00020626,  0.01056263, ...,  0.00072511,\n",
      "        0.0002657 ,  0.00020626], dtype=float32)]\n",
      "ACC@TRAIN: 0.1023\n",
      "ACC@DEV: 0.103333\n",
      "LOSS, Softmax_loss, Center_loss [3.7518895, array([ 2.28921127,  2.27796793,  2.28921127, ...,  2.30741715,\n",
      "        2.31173277,  2.27796793], dtype=float32), array([ 0.00892574,  0.00014832,  0.00892574, ...,  0.00051193,\n",
      "        0.0002058 ,  0.00014832], dtype=float32)]\n",
      "ACC@TRAIN: 0.1026\n",
      "ACC@DEV: 0.1035\n",
      "LOSS, Softmax_loss, Center_loss [3.4783528, array([ 2.28831005,  2.27837253,  2.28831005, ...,  2.30741382,\n",
      "        2.31108427,  2.27837253], dtype=float32), array([ 0.00759772,  0.00011206,  0.00759772, ...,  0.00036207,\n",
      "        0.00016012,  0.00011206], dtype=float32)]\n",
      "ACC@TRAIN: 0.102833\n",
      "ACC@DEV: 0.103583\n",
      "LOSS, Softmax_loss, Center_loss [3.2595601, array([ 2.28739524,  2.27878451,  2.28739524, ...,  2.30740786,\n",
      "        2.3104341 ,  2.27878451], dtype=float32), array([  6.49786787e-03,   8.85726913e-05,   6.49786787e-03, ...,\n",
      "         2.55576771e-04,   1.25425635e-04,   8.85726913e-05], dtype=float32)]\n",
      "ACC@TRAIN: 0.103033\n",
      "ACC@DEV: 0.10375\n",
      "LOSS, Softmax_loss, Center_loss [3.0837677, array([ 2.28646731,  2.27920318,  2.28646731, ...,  2.30739856,\n",
      "        2.30978322,  2.27920318], dtype=float32), array([  5.57449833e-03,   7.05352504e-05,   5.57449833e-03, ...,\n",
      "         1.80596224e-04,   9.91384950e-05,   7.05352504e-05], dtype=float32)]\n",
      "ACC@TRAIN: 0.103333\n",
      "ACC@DEV: 0.103917\n",
      "LOSS, Softmax_loss, Center_loss [2.9417093, array([ 2.28552794,  2.27962875,  2.28552794, ...,  2.30738711,\n",
      "        2.30913305,  2.27962875], dtype=float32), array([  4.79495618e-03,   5.78849103e-05,   4.79495618e-03, ...,\n",
      "         1.28588479e-04,   7.84885051e-05,   5.78849103e-05], dtype=float32)]\n",
      "ACC@TRAIN: 0.1033\n",
      "ACC@DEV: 0.103833\n",
      "LOSS, Softmax_loss, Center_loss [2.8264391, array([ 2.28457713,  2.28006005,  2.28457713, ...,  2.30737257,\n",
      "        2.3084836 ,  2.28006005], dtype=float32), array([  4.13575675e-03,   4.76864880e-05,   4.13575675e-03, ...,\n",
      "         9.26104985e-05,   6.21814906e-05,   4.76864880e-05], dtype=float32)]\n",
      "ACC@TRAIN: 0.103467\n",
      "ACC@DEV: 0.104\n",
      "LOSS, Softmax_loss, Center_loss [2.7326558, array([ 2.28361583,  2.28049731,  2.28361583, ...,  2.3073554 ,\n",
      "        2.30783606,  2.28049731], dtype=float32), array([  3.57369496e-03,   3.93113478e-05,   3.57369496e-03, ...,\n",
      "         6.78611250e-05,   4.93015214e-05,   3.93113478e-05], dtype=float32)]\n",
      "ACC@TRAIN: 0.103467\n",
      "ACC@DEV: 0.104333\n",
      "LOSS, Softmax_loss, Center_loss [2.6563542, array([ 2.28264546,  2.28094006,  2.28264546, ...,  2.30733562,\n",
      "        2.3071909 ,  2.28094006], dtype=float32), array([  3.09491064e-03,   3.24847606e-05,   3.09491064e-03, ...,\n",
      "         5.06049255e-05,   3.91204339e-05,   3.24847606e-05], dtype=float32)]\n",
      "ACC@TRAIN: 0.103433\n",
      "ACC@DEV: 0.104333\n",
      "LOSS, Softmax_loss, Center_loss [2.5941226, array([ 2.28166604,  2.28138733,  2.28166604, ...,  2.30731249,\n",
      "        2.3065486 ,  2.28138733], dtype=float32), array([  2.68754340e-03,   2.68504100e-05,   2.68754340e-03, ...,\n",
      "         3.79852427e-05,   3.11430340e-05,   2.68504100e-05], dtype=float32)]\n",
      "ACC@TRAIN: 0.1034\n",
      "ACC@DEV: 0.104333\n",
      "LOSS, Softmax_loss, Center_loss [2.543417, array([ 2.28067899,  2.28183937,  2.28067899, ...,  2.30728698,\n",
      "        2.30590987,  2.28183937], dtype=float32), array([  2.33810931e-03,   2.22009403e-05,   2.33810931e-03, ...,\n",
      "         2.86733666e-05,   2.47726093e-05,   2.22009403e-05], dtype=float32)]\n",
      "ACC@TRAIN: 0.103433\n",
      "ACC@DEV: 0.104333\n"
     ]
    }
   ],
   "source": [
    "##构图\n",
    "xs = tf.placeholder(tf.float32, [None, 784])\n",
    "ys = tf.placeholder(tf.int64, [None, 1])\n",
    "\n",
    "ys_one_hot = tf.one_hot(ys, 10)\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "with tf.variable_scope('center'):\n",
    "    centers = tf.get_variable('centers', [10, 1024], dtype=tf.float32,\\\n",
    "                          initializer=tf.constant_initializer(0), trainable=False)\n",
    "#------CNN1-------#\n",
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])\n",
    "\n",
    "x_image = tf.reshape(xs, [-1,28,28,1])\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "#-------CNN2-------#\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "#-------DNN------#\n",
    "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "s_fc1 = scale_variable([1024])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "\n",
    "h_fc1 = DNN(h_pool2_flat, W_fc1, b_fc1, tf.nn.relu)\n",
    "\n",
    "center_loss = get_center_loss(h_fc1, ys)\n",
    "\n",
    "update_centers = update_centers(h_fc1, ys, 0.5)\n",
    "\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "#-------DNN2-----#\n",
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "\n",
    "#----------------#\n",
    "softmax_loss = tf.nn.softmax_cross_entropy_with_logits(labels=ys_one_hot, logits=y_conv)\n",
    "\n",
    "loss = tf.reduce_mean(softmax_loss + 1.0 * center_loss)\n",
    "\n",
    "train_op = tf.train.AdamOptimizer(1e-4).minimize(loss)\n",
    "\n",
    "result = tf.argmax(y_conv,1)\n",
    "\n",
    "ground_truth = tf.reshape(ys, [-1])\n",
    "\n",
    "correct_prediction = tf.equal(result, ground_truth)\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for i in range(30):\n",
    "        print 'LOSS, Softmax_loss, Center_loss', sess.run([loss, softmax_loss, center_loss], feed_dict = {xs: x_train, ys: y_train.values, keep_prob:1.0})\n",
    "        print 'ACC@TRAIN:', sess.run(accuracy, feed_dict = {xs: x_train, ys: y_train.values, keep_prob:1.0})\n",
    "        print 'ACC@DEV:', sess.run(accuracy, feed_dict = {xs: x_dev, ys: y_dev.values, keep_prob:1.0})\n",
    "        j = 0\n",
    "        while j < 30000:       \n",
    "            _, cen = sess.run([train_op, update_centers], feed_dict = {xs: x_train[j:j+1000], ys: y_train[j:j+1000].values, keep_prob:1.0})\n",
    "            \n",
    "            j += 1000  \n",
    "    pd.DataFrame({\"ImageId\": range(1, len(x_test) + 1), \"Label\": sess.run(result, feed_dict = {xs: x_test, keep_prob:1.0})}).to_csv('MNIST_data/CENTER_LOSS.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
