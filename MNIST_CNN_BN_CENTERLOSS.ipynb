{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mnist_train = pd.read_csv('MNIST_data/train.csv')\n",
    "mnist_test = pd.read_csv('MNIST_data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 784) (30000, 1) (12000, 784) (12000, 1) (28000, 784)\n"
     ]
    }
   ],
   "source": [
    "y_train = mnist_train[['label']][:30000]\n",
    "x_train = mnist_train[['pixel' + str(idx) for idx in range(784)]][:30000]\n",
    "\n",
    "y_dev = mnist_train[['label']][30000:42000]\n",
    "x_dev = mnist_train[['pixel' + str(idx) for idx in range(784)]][30000:42000]\n",
    "\n",
    "x_test = mnist_test[['pixel' + str(idx) for idx in range(784)]]\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_dev = scaler.transform(x_dev)\n",
    "x_test = scaler.transform(x_test)\n",
    "\n",
    "\n",
    "print x_train.shape, y_train.shape, x_dev.shape, y_dev.shape, x_test.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EPSILON = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def DNN_BN(x, weights, beta, scale, activation_function = None):\n",
    "    wx = tf.matmul(x, weights)\n",
    "    mean, var = tf.nn.moments(wx, [0])\n",
    "    bn = tf.nn.batch_normalization(wx, mean, var, beta, scale, EPSILON)\n",
    "    if not activation_function:\n",
    "        return bn\n",
    "    else:\n",
    "        return activation_function(bn)\n",
    "    \n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "def scale_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "      return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "def max_pool_2x2(x):\n",
    "      return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    \n",
    "def get_center_loss(features, labels):\n",
    "    with tf.variable_scope('center', reuse=True):\n",
    "        centers = tf.get_variable('centers')\n",
    "    \n",
    "    len_features = features.get_shape()[1]\n",
    "    labels = tf.reshape(labels, [-1])\n",
    "\n",
    "    centers_batch = tf.gather(centers, labels)\n",
    "    # 计算center loss的数值\n",
    "    loss = tf.reduce_sum((features - centers_batch) ** 2, [1])\n",
    " \n",
    "    return loss\n",
    "\n",
    "def update_centers(features, labels, alpha):\n",
    "    with tf.variable_scope('center', reuse=True):\n",
    "        centers = tf.get_variable('centers')\n",
    "    \n",
    "    labels = tf.reshape(labels, [-1])\n",
    "    centers_batch = tf.gather(centers, labels)\n",
    "    \n",
    "    diff = centers_batch - features\n",
    "\n",
    "        # 获取一个batch中同一样本出现的次数，这里需要理解论文中的更新公式\n",
    "    unique_label, unique_idx, unique_count = tf.unique_with_counts(labels)\n",
    "    appear_times = tf.gather(unique_count, unique_idx)\n",
    "    appear_times = tf.reshape(appear_times, [-1, 1])\n",
    "\n",
    "    diff = diff / tf.cast((1 + appear_times), tf.float32)\n",
    "    diff = alpha * diff\n",
    "        # 更新中心\n",
    "    centers = tf.scatter_sub(centers,labels, diff)\n",
    "    \n",
    "    return centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS, Softmax_loss, Center_loss [20.845671, array([ 1.89118171,  2.59083939,  1.85489595, ...,  2.85570526,\n",
      "        2.36184478,  2.52042532], dtype=float32), array([ 13.56688023,  15.45531273,  12.73999023, ...,  12.15333843,\n",
      "        14.88640881,  15.39474392], dtype=float32)]\n",
      "ACC@TRAIN: 0.117667\n",
      "ACC@DEV: 0.111583\n",
      "LOSS, Softmax_loss, Center_loss [5.7340636, array([ 1.32175148,  1.45729852,  1.04180515, ...,  2.40533781,\n",
      "        1.89451623,  1.73244917], dtype=float32), array([ 2.11202526,  1.95618939,  0.52589446, ...,  2.37727499,\n",
      "        3.84187102,  3.18874836], dtype=float32)]\n",
      "ACC@TRAIN: 0.625333\n",
      "ACC@DEV: 0.587333\n",
      "LOSS, Softmax_loss, Center_loss [4.2568178, array([ 1.09973609,  0.93553668,  0.77573693, ...,  2.12570477,\n",
      "        1.72439861,  1.33488047], dtype=float32), array([ 1.58081937,  1.41841698,  0.33646801, ...,  2.02794886,\n",
      "        2.87877464,  2.32689047], dtype=float32)]\n",
      "ACC@TRAIN: 0.749267\n",
      "ACC@DEV: 0.739167\n",
      "LOSS, Softmax_loss, Center_loss [3.477864, array([ 0.95876896,  0.64245301,  0.63781333, ...,  1.90493441,\n",
      "        1.62028408,  1.01649404], dtype=float32), array([ 1.22546053,  1.09051144,  0.24125658, ...,  1.92803168,\n",
      "        2.35214686,  1.7498455 ], dtype=float32)]\n",
      "ACC@TRAIN: 0.804733\n",
      "ACC@DEV: 0.803083\n",
      "LOSS, Softmax_loss, Center_loss [3.0005858, array([ 0.85238636,  0.45315433,  0.53337991, ...,  1.7152158 ,\n",
      "        1.53541589,  0.78915453], dtype=float32), array([ 0.97869414,  0.8899169 ,  0.19501549, ...,  1.87999368,\n",
      "        2.08271742,  1.38928246], dtype=float32)]\n",
      "ACC@TRAIN: 0.837467\n",
      "ACC@DEV: 0.834667\n",
      "LOSS, Softmax_loss, Center_loss [2.6658175, array([ 0.77643973,  0.33664933,  0.4569535 , ...,  1.55904043,\n",
      "        1.4684633 ,  0.64257336], dtype=float32), array([ 0.80949509,  0.76236069,  0.16564247, ...,  1.83359098,\n",
      "        1.89764249,  1.15564799], dtype=float32)]\n",
      "ACC@TRAIN: 0.860067\n",
      "ACC@DEV: 0.8565\n",
      "LOSS, Softmax_loss, Center_loss [2.4127452, array([ 0.70759279,  0.26543528,  0.39533129, ...,  1.43616188,\n",
      "        1.42014182,  0.54363728], dtype=float32), array([ 0.68770581,  0.67452222,  0.1464684 , ...,  1.7850163 ,\n",
      "        1.75808144,  0.9868986 ], dtype=float32)]\n",
      "ACC@TRAIN: 0.876333\n",
      "ACC@DEV: 0.871833\n",
      "LOSS, Softmax_loss, Center_loss [2.2125332, array([ 0.64764178,  0.22004102,  0.34756327, ...,  1.33647311,\n",
      "        1.38313413,  0.47482601], dtype=float32), array([ 0.59577501,  0.60878956,  0.1320498 , ...,  1.73160386,\n",
      "        1.65152693,  0.86121249], dtype=float32)]\n",
      "ACC@TRAIN: 0.888133\n",
      "ACC@DEV: 0.884667\n",
      "LOSS, Softmax_loss, Center_loss [2.0489156, array([ 0.59261441,  0.18895017,  0.30859336, ...,  1.25512803,\n",
      "        1.35242081,  0.42421526], dtype=float32), array([ 0.52621078,  0.55648506,  0.12086625, ...,  1.67459166,\n",
      "        1.56261599,  0.76380283], dtype=float32)]\n",
      "ACC@TRAIN: 0.896933\n",
      "ACC@DEV: 0.893333\n",
      "LOSS, Softmax_loss, Center_loss [1.9118139, array([ 0.54144228,  0.16645238,  0.2761814 , ...,  1.18657422,\n",
      "        1.32005715,  0.3853555 ], dtype=float32), array([ 0.4712933 ,  0.51272881,  0.11165313, ...,  1.6138823 ,\n",
      "        1.48043108,  0.68927246], dtype=float32)]\n",
      "ACC@TRAIN: 0.9042\n",
      "ACC@DEV: 0.901417\n",
      "LOSS, Softmax_loss, Center_loss [1.7943941, array([ 0.49443415,  0.14942473,  0.24926417, ...,  1.12665868,\n",
      "        1.28837657,  0.3550013 ], dtype=float32), array([ 0.42577043,  0.47346193,  0.10338656, ...,  1.55080295,\n",
      "        1.40694857,  0.6325804 ], dtype=float32)]\n",
      "ACC@TRAIN: 0.910367\n",
      "ACC@DEV: 0.907917\n",
      "LOSS, Softmax_loss, Center_loss [1.6919882, array([ 0.452636  ,  0.13639694,  0.22632584, ...,  1.07180333,\n",
      "        1.25503838,  0.33051756], dtype=float32), array([ 0.38860574,  0.4378708 ,  0.09635266, ...,  1.48515749,\n",
      "        1.34105182,  0.58991325], dtype=float32)]\n",
      "ACC@TRAIN: 0.915233\n",
      "ACC@DEV: 0.913667\n",
      "LOSS, Softmax_loss, Center_loss [1.6012956, array([ 0.41613603,  0.12583178,  0.20666571, ...,  1.02073717,\n",
      "        1.22089493,  0.31050935], dtype=float32), array([ 0.35662434,  0.40544748,  0.09047586, ...,  1.41811454,\n",
      "        1.28156352,  0.5569343 ], dtype=float32)]\n",
      "ACC@TRAIN: 0.9196\n",
      "ACC@DEV: 0.9175\n",
      "LOSS, Softmax_loss, Center_loss [1.5200216, array([ 0.3838377 ,  0.11703572,  0.18996236, ...,  0.97395027,\n",
      "        1.18651152,  0.2937744 ], dtype=float32), array([ 0.32911098,  0.37672684,  0.08544114, ...,  1.35179996,\n",
      "        1.2255615 ,  0.53131306], dtype=float32)]\n",
      "ACC@TRAIN: 0.923933\n",
      "ACC@DEV: 0.9225\n",
      "LOSS, Softmax_loss, Center_loss [1.4464432, array([ 0.35513195,  0.10953768,  0.17551948, ...,  0.92983031,\n",
      "        1.15118849,  0.27961093], dtype=float32), array([ 0.30472085,  0.35130727,  0.08138919, ...,  1.28711247,\n",
      "        1.17224705,  0.51215768], dtype=float32)]\n",
      "ACC@TRAIN: 0.928433\n",
      "ACC@DEV: 0.9275\n",
      "LOSS, Softmax_loss, Center_loss [1.3793659, array([ 0.32935408,  0.10312367,  0.16307075, ...,  0.88841128,\n",
      "        1.11553597,  0.26772442], dtype=float32), array([ 0.28274715,  0.32889825,  0.0779836 , ...,  1.22577047,\n",
      "        1.12303412,  0.49671268], dtype=float32)]\n",
      "ACC@TRAIN: 0.931967\n",
      "ACC@DEV: 0.93075\n",
      "LOSS, Softmax_loss, Center_loss [1.3178161, array([ 0.30604142,  0.09775858,  0.15228514, ...,  0.84849006,\n",
      "        1.07844782,  0.2574994 ], dtype=float32), array([ 0.26306909,  0.30916819,  0.0751638 , ...,  1.16611004,\n",
      "        1.07621396,  0.48511225], dtype=float32)]\n",
      "ACC@TRAIN: 0.935067\n",
      "ACC@DEV: 0.933583\n",
      "LOSS, Softmax_loss, Center_loss [1.2610879, array([ 0.28521168,  0.09299215,  0.14285471, ...,  0.81063265,\n",
      "        1.04133475,  0.24817868], dtype=float32), array([ 0.24500327,  0.29216325,  0.07278262, ...,  1.10890317,\n",
      "        1.03169906,  0.47550318], dtype=float32)]\n",
      "ACC@TRAIN: 0.937967\n",
      "ACC@DEV: 0.937\n",
      "LOSS, Softmax_loss, Center_loss [1.2085769, array([ 0.26647753,  0.08875611,  0.13434179, ...,  0.77414739,\n",
      "        1.0023005 ,  0.23978347], dtype=float32), array([ 0.22873671,  0.2773765 ,  0.07073602, ...,  1.05375755,\n",
      "        0.98767048,  0.46772513], dtype=float32)]\n",
      "ACC@TRAIN: 0.940467\n",
      "ACC@DEV: 0.939417\n",
      "LOSS, Softmax_loss, Center_loss [1.1598115, array([ 0.24942897,  0.08493871,  0.12653077, ...,  0.7392748 ,\n",
      "        0.96513045,  0.23182283], dtype=float32), array([ 0.21392499,  0.26441491,  0.06910747, ...,  1.00131714,\n",
      "        0.94555163,  0.4614737 ], dtype=float32)]\n",
      "ACC@TRAIN: 0.9427\n",
      "ACC@DEV: 0.942417\n",
      "LOSS, Softmax_loss, Center_loss [1.1143975, array([ 0.234166  ,  0.08165693,  0.11962183, ...,  0.70577991,\n",
      "        0.92913562,  0.22445667], dtype=float32), array([ 0.20076984,  0.25292641,  0.06760718, ...,  0.95165354,\n",
      "        0.90564531,  0.4553284 ], dtype=float32)]\n",
      "ACC@TRAIN: 0.9455\n",
      "ACC@DEV: 0.944\n",
      "LOSS, Softmax_loss, Center_loss [1.0719935, array([ 0.22057143,  0.07877616,  0.11337839, ...,  0.67453241,\n",
      "        0.8938216 ,  0.21744843], dtype=float32), array([ 0.1891304 ,  0.24244078,  0.06635214, ...,  0.90482795,\n",
      "        0.8676194 ,  0.44941247], dtype=float32)]\n",
      "ACC@TRAIN: 0.947233\n",
      "ACC@DEV: 0.946083\n",
      "LOSS, Softmax_loss, Center_loss [1.0323354, array([ 0.20818871,  0.07624546,  0.10778748, ...,  0.64520365,\n",
      "        0.85905123,  0.21113007], dtype=float32), array([ 0.17843127,  0.2325318 ,  0.06508956, ...,  0.86027902,\n",
      "        0.83152664,  0.4437297 ], dtype=float32)]\n",
      "ACC@TRAIN: 0.950133\n",
      "ACC@DEV: 0.94725\n",
      "LOSS, Softmax_loss, Center_loss [0.99516875, array([ 0.1967881 ,  0.07396876,  0.10261849, ...,  0.61719966,\n",
      "        0.82554281,  0.20479229], dtype=float32), array([ 0.1686552 ,  0.22348513,  0.06403711, ...,  0.81764805,\n",
      "        0.79679173,  0.43815336], dtype=float32)]\n",
      "ACC@TRAIN: 0.951867\n",
      "ACC@DEV: 0.948417\n",
      "LOSS, Softmax_loss, Center_loss [0.9602688, array([ 0.1864334 ,  0.07175277,  0.09781555, ...,  0.59058094,\n",
      "        0.79316276,  0.19866481], dtype=float32), array([ 0.15980966,  0.21551508,  0.06316441, ...,  0.77717388,\n",
      "        0.76380771,  0.432769  ], dtype=float32)]\n",
      "ACC@TRAIN: 0.953433\n",
      "ACC@DEV: 0.950583\n",
      "LOSS, Softmax_loss, Center_loss [0.92741966, array([ 0.17685695,  0.06977281,  0.093312  , ...,  0.56542093,\n",
      "        0.76211667,  0.19272709], dtype=float32), array([ 0.15160201,  0.20800945,  0.06242164, ...,  0.73927164,\n",
      "        0.73288476,  0.42758554], dtype=float32)]\n",
      "ACC@TRAIN: 0.955067\n",
      "ACC@DEV: 0.952583\n",
      "LOSS, Softmax_loss, Center_loss [0.89646477, array([ 0.16801849,  0.06787726,  0.08910871, ...,  0.54147005,\n",
      "        0.73335499,  0.18675646], dtype=float32), array([ 0.14381671,  0.20094875,  0.06173597, ...,  0.70336223,\n",
      "        0.70490009,  0.42229998], dtype=float32)]\n",
      "ACC@TRAIN: 0.9566\n",
      "ACC@DEV: 0.954333\n",
      "LOSS, Softmax_loss, Center_loss [0.86726063, array([ 0.15970662,  0.06615698,  0.08518561, ...,  0.51894224,\n",
      "        0.70617473,  0.18106593], dtype=float32), array([ 0.13656268,  0.19424593,  0.06119989, ...,  0.66933751,\n",
      "        0.67902821,  0.41697526], dtype=float32)]\n",
      "ACC@TRAIN: 0.957867\n",
      "ACC@DEV: 0.955833\n",
      "LOSS, Softmax_loss, Center_loss [0.83966964, array([ 0.15195742,  0.06460138,  0.08161189, ...,  0.49788964,\n",
      "        0.68022597,  0.17556189], dtype=float32), array([ 0.12995726,  0.18787159,  0.06073504, ...,  0.63747919,\n",
      "        0.65456653,  0.41157961], dtype=float32)]\n",
      "ACC@TRAIN: 0.959033\n",
      "ACC@DEV: 0.957417\n",
      "LOSS, Softmax_loss, Center_loss [0.8135587, array([ 0.14476778,  0.06311476,  0.07823625, ...,  0.47825509,\n",
      "        0.65592802,  0.17003684], dtype=float32), array([ 0.12375256,  0.18200558,  0.06039236, ...,  0.60735852,\n",
      "        0.63177013,  0.40558958], dtype=float32)]\n",
      "ACC@TRAIN: 0.960133\n",
      "ACC@DEV: 0.958417\n",
      "LOSS, Softmax_loss, Center_loss [0.78880781, array([ 0.13814227,  0.06172209,  0.07508199, ...,  0.45949119,\n",
      "        0.63324082,  0.16449554], dtype=float32), array([ 0.11807968,  0.17657934,  0.06014512, ...,  0.57863724,\n",
      "        0.61005473,  0.39930448], dtype=float32)]\n",
      "ACC@TRAIN: 0.9613\n",
      "ACC@DEV: 0.95975\n",
      "LOSS, Softmax_loss, Center_loss [0.76531017, array([ 0.13201301,  0.06039134,  0.07203822, ...,  0.44126874,\n",
      "        0.61262834,  0.15911496], dtype=float32), array([ 0.1127647 ,  0.17117423,  0.05995439, ...,  0.55152428,\n",
      "        0.59004211,  0.39330217], dtype=float32)]\n",
      "ACC@TRAIN: 0.962733\n",
      "ACC@DEV: 0.960917\n",
      "LOSS, Softmax_loss, Center_loss [0.74299306, array([ 0.12634492,  0.05911421,  0.06918697, ...,  0.42425925,\n",
      "        0.59297532,  0.15385203], dtype=float32), array([ 0.1078701 ,  0.16600838,  0.05979212, ...,  0.52614212,\n",
      "        0.5711925 ,  0.38693935], dtype=float32)]\n",
      "ACC@TRAIN: 0.9636\n",
      "ACC@DEV: 0.961917\n",
      "LOSS, Softmax_loss, Center_loss [0.7217775, array([ 0.12104511,  0.0579376 ,  0.06650081, ...,  0.40849367,\n",
      "        0.57497817,  0.14875823], dtype=float32), array([ 0.10331169,  0.16098864,  0.05967078, ...,  0.50253546,\n",
      "        0.55377394,  0.38049829], dtype=float32)]\n",
      "ACC@TRAIN: 0.964733\n",
      "ACC@DEV: 0.962917\n",
      "LOSS, Softmax_loss, Center_loss [0.70158821, array([ 0.11609456,  0.05671174,  0.06393009, ...,  0.39337248,\n",
      "        0.55801934,  0.14383142], dtype=float32), array([ 0.09903099,  0.15641156,  0.05962191, ...,  0.48019224,\n",
      "        0.53784406,  0.37401444], dtype=float32)]\n",
      "ACC@TRAIN: 0.965367\n",
      "ACC@DEV: 0.964083\n",
      "LOSS, Softmax_loss, Center_loss [0.68236345, array([ 0.11153074,  0.05547681,  0.06154735, ...,  0.37901846,\n",
      "        0.54250932,  0.13930613], dtype=float32), array([ 0.09510921,  0.15207556,  0.05948094, ...,  0.4592042 ,\n",
      "        0.52295798,  0.36767945], dtype=float32)]\n",
      "ACC@TRAIN: 0.965967\n",
      "ACC@DEV: 0.965333\n",
      "LOSS, Softmax_loss, Center_loss [0.66403764, array([ 0.10722403,  0.05424409,  0.05931769, ...,  0.36503905,\n",
      "        0.52767307,  0.13485704], dtype=float32), array([ 0.09149653,  0.14791453,  0.0593721 , ...,  0.43933579,\n",
      "        0.508708  ,  0.36148852], dtype=float32)]\n",
      "ACC@TRAIN: 0.966633\n",
      "ACC@DEV: 0.96625\n",
      "LOSS, Softmax_loss, Center_loss [0.64654726, array([ 0.10322776,  0.05314391,  0.05715048, ...,  0.35172716,\n",
      "        0.51393652,  0.13085538], dtype=float32), array([ 0.08818124,  0.14366776,  0.05927182, ...,  0.42078012,\n",
      "        0.49531496,  0.35573512], dtype=float32)]\n",
      "ACC@TRAIN: 0.9677\n",
      "ACC@DEV: 0.967\n",
      "LOSS, Softmax_loss, Center_loss [0.6298492, array([ 0.0995237 ,  0.05208327,  0.05513966, ...,  0.33884811,\n",
      "        0.50081658,  0.12709488], dtype=float32), array([ 0.08512027,  0.13970833,  0.05915758, ...,  0.40281984,\n",
      "        0.48261333,  0.35042232], dtype=float32)]\n",
      "ACC@TRAIN: 0.968533\n",
      "ACC@DEV: 0.967917\n",
      "LOSS, Softmax_loss, Center_loss [0.61389357, array([ 0.0960043 ,  0.0510616 ,  0.05322191, ...,  0.32661217,\n",
      "        0.48871478,  0.12358675], dtype=float32), array([ 0.08214195,  0.13603863,  0.05902728, ...,  0.3859252 ,\n",
      "        0.47063416,  0.34510562], dtype=float32)]\n",
      "ACC@TRAIN: 0.969233\n",
      "ACC@DEV: 0.968333\n",
      "LOSS, Softmax_loss, Center_loss [0.59863698, array([ 0.09272131,  0.05006779,  0.0514496 , ...,  0.31476465,\n",
      "        0.4775036 ,  0.12017739], dtype=float32), array([ 0.07941951,  0.13250265,  0.05886121, ...,  0.37001345,\n",
      "        0.45965403,  0.3400532 ], dtype=float32)]\n",
      "ACC@TRAIN: 0.969733\n",
      "ACC@DEV: 0.969083\n",
      "LOSS, Softmax_loss, Center_loss [0.58403784, array([ 0.08971068,  0.04911897,  0.04972667, ...,  0.30343401,\n",
      "        0.46707994,  0.11692139], dtype=float32), array([ 0.07689247,  0.12894003,  0.05873699, ...,  0.35508549,\n",
      "        0.44914156,  0.33501863], dtype=float32)]\n",
      "ACC@TRAIN: 0.970133\n",
      "ACC@DEV: 0.969833\n",
      "LOSS, Softmax_loss, Center_loss [0.57005131, array([ 0.08686475,  0.0482173 ,  0.04806291, ...,  0.29275665,\n",
      "        0.45732656,  0.11392233], dtype=float32), array([ 0.07460153,  0.12555331,  0.05859692, ...,  0.34075153,\n",
      "        0.4394505 ,  0.33011675], dtype=float32)]\n",
      "ACC@TRAIN: 0.970567\n",
      "ACC@DEV: 0.970417\n",
      "LOSS, Softmax_loss, Center_loss [0.55663908, array([ 0.08423722,  0.04730878,  0.04652531, ...,  0.28246117,\n",
      "        0.44823474,  0.11082749], dtype=float32), array([ 0.07231999,  0.12240435,  0.05843163, ...,  0.32715622,\n",
      "        0.43037647,  0.3249262 ], dtype=float32)]\n",
      "ACC@TRAIN: 0.9712\n",
      "ACC@DEV: 0.970833\n",
      "LOSS, Softmax_loss, Center_loss [0.54377884, array([ 0.0816756 ,  0.04640184,  0.0450414 , ...,  0.27302077,\n",
      "        0.43911543,  0.10783704], dtype=float32), array([ 0.07024807,  0.11939287,  0.05830899, ...,  0.31441551,\n",
      "        0.42147318,  0.31979725], dtype=float32)]\n",
      "ACC@TRAIN: 0.971833\n",
      "ACC@DEV: 0.971333\n",
      "LOSS, Softmax_loss, Center_loss [0.53143561, array([ 0.0791116 ,  0.04553404,  0.04360483, ...,  0.26394534,\n",
      "        0.43058306,  0.10493797], dtype=float32), array([ 0.06840803,  0.11656268,  0.0581762 , ...,  0.30204988,\n",
      "        0.41302136,  0.31489998], dtype=float32)]\n",
      "ACC@TRAIN: 0.9724\n",
      "ACC@DEV: 0.972\n",
      "LOSS, Softmax_loss, Center_loss [0.51958215, array([ 0.07676978,  0.04475157,  0.04225853, ...,  0.25536263,\n",
      "        0.42226595,  0.10215685], dtype=float32), array([ 0.06663024,  0.11389118,  0.05803089, ...,  0.29045331,\n",
      "        0.40479362,  0.30982071], dtype=float32)]\n",
      "ACC@TRAIN: 0.972933\n",
      "ACC@DEV: 0.97275\n",
      "LOSS, Softmax_loss, Center_loss [0.50819343, array([ 0.07453267,  0.0439727 ,  0.04098594, ...,  0.24678741,\n",
      "        0.41439727,  0.09939279], dtype=float32), array([ 0.06496292,  0.11142304,  0.05780312, ...,  0.27927232,\n",
      "        0.39694399,  0.30452269], dtype=float32)]\n",
      "ACC@TRAIN: 0.973633\n",
      "ACC@DEV: 0.973083\n",
      "LOSS, Softmax_loss, Center_loss [0.49724385, array([ 0.07239356,  0.04317826,  0.03980933, ...,  0.2384664 ,\n",
      "        0.40720165,  0.09679066], dtype=float32), array([ 0.06341082,  0.10908121,  0.05759644, ...,  0.26880378,\n",
      "        0.38977039,  0.29937845], dtype=float32)]\n",
      "ACC@TRAIN: 0.974067\n",
      "ACC@DEV: 0.973583\n",
      "LOSS, Softmax_loss, Center_loss [0.48671076, array([ 0.07031276,  0.04236297,  0.03869728, ...,  0.23032822,\n",
      "        0.40031713,  0.09424651], dtype=float32), array([ 0.06190002,  0.10697614,  0.05731253, ...,  0.25866103,\n",
      "        0.38282937,  0.29421484], dtype=float32)]\n",
      "ACC@TRAIN: 0.974367\n",
      "ACC@DEV: 0.974333\n",
      "LOSS, Softmax_loss, Center_loss [0.47657403, array([ 0.06829866,  0.04162443,  0.03765827, ...,  0.22284605,\n",
      "        0.39328167,  0.09178537], dtype=float32), array([ 0.0605038 ,  0.10503883,  0.05701578, ...,  0.24904692,\n",
      "        0.37593934,  0.28889343], dtype=float32)]\n",
      "ACC@TRAIN: 0.974733\n",
      "ACC@DEV: 0.97475\n",
      "LOSS, Softmax_loss, Center_loss [0.46681407, array([ 0.06638401,  0.0408738 ,  0.03666301, ...,  0.21585616,\n",
      "        0.38617268,  0.08942882], dtype=float32), array([ 0.05914249,  0.1033008 ,  0.05674851, ...,  0.24006416,\n",
      "        0.36902368,  0.28381687], dtype=float32)]\n",
      "ACC@TRAIN: 0.9752\n",
      "ACC@DEV: 0.97525\n",
      "LOSS, Softmax_loss, Center_loss [0.45740664, array([ 0.06452784,  0.04014928,  0.03571586, ...,  0.20904768,\n",
      "        0.37920427,  0.0871422 ], dtype=float32), array([ 0.05790195,  0.1016643 ,  0.05640625, ...,  0.23157996,\n",
      "        0.36223856,  0.27866399], dtype=float32)]\n",
      "ACC@TRAIN: 0.9758\n",
      "ACC@DEV: 0.975583\n",
      "LOSS, Softmax_loss, Center_loss [0.44833717, array([ 0.06277492,  0.03941242,  0.03483725, ...,  0.20244025,\n",
      "        0.37230185,  0.08494134], dtype=float32), array([ 0.05675561,  0.10004095,  0.05602779, ...,  0.22358049,\n",
      "        0.35558039,  0.27402738], dtype=float32)]\n",
      "ACC@TRAIN: 0.9764\n",
      "ACC@DEV: 0.976167\n",
      "LOSS, Softmax_loss, Center_loss [0.43959081, array([ 0.06111155,  0.03875611,  0.033974  , ...,  0.1962119 ,\n",
      "        0.3651337 ,  0.082839  ], dtype=float32), array([ 0.05563398,  0.09829547,  0.05561212, ...,  0.21614777,\n",
      "        0.34883058,  0.26922685], dtype=float32)]\n",
      "ACC@TRAIN: 0.976733\n",
      "ACC@DEV: 0.976417\n",
      "LOSS, Softmax_loss, Center_loss [0.43114629, array([ 0.05951157,  0.03808846,  0.0331567 , ...,  0.19022219,\n",
      "        0.35814413,  0.08081613], dtype=float32), array([ 0.05456436,  0.09651808,  0.05518785, ...,  0.2089662 ,\n",
      "        0.34225905,  0.26463971], dtype=float32)]\n",
      "ACC@TRAIN: 0.977067\n",
      "ACC@DEV: 0.976583\n",
      "LOSS, Softmax_loss, Center_loss [0.42299151, array([ 0.05802321,  0.03747676,  0.03236678, ...,  0.18447369,\n",
      "        0.35163146,  0.07887069], dtype=float32), array([ 0.05350712,  0.09474096,  0.05479503, ...,  0.20218426,\n",
      "        0.33612099,  0.2601248 ], dtype=float32)]\n",
      "ACC@TRAIN: 0.9776\n",
      "ACC@DEV: 0.976833\n",
      "LOSS, Softmax_loss, Center_loss [0.41511413, array([ 0.05657442,  0.03681847,  0.03161574, ...,  0.17887868,\n",
      "        0.34519029,  0.07690644], dtype=float32), array([ 0.05249782,  0.09295899,  0.05440418, ...,  0.19573402,\n",
      "        0.33008862,  0.25553149], dtype=float32)]\n",
      "ACC@TRAIN: 0.9779\n",
      "ACC@DEV: 0.977417\n",
      "LOSS, Softmax_loss, Center_loss [0.40749693, array([ 0.0552007 ,  0.03619598,  0.0308943 , ...,  0.17358144,\n",
      "        0.33897904,  0.0750821 ], dtype=float32), array([ 0.0515265 ,  0.0912233 ,  0.05402116, ...,  0.18964919,\n",
      "        0.32452592,  0.25118375], dtype=float32)]\n",
      "ACC@TRAIN: 0.9785\n",
      "ACC@DEV: 0.97775\n",
      "LOSS, Softmax_loss, Center_loss [0.40013164, array([ 0.05388461,  0.03561935,  0.03021571, ...,  0.16861983,\n",
      "        0.33287448,  0.07330694], dtype=float32), array([ 0.05064128,  0.08961131,  0.05358125, ...,  0.18376359,\n",
      "        0.31916082,  0.24705149], dtype=float32)]\n",
      "ACC@TRAIN: 0.978767\n",
      "ACC@DEV: 0.978\n"
     ]
    }
   ],
   "source": [
    "##构图\n",
    "\n",
    "xs = tf.placeholder(tf.float32, [None, 784])\n",
    "ys = tf.placeholder(tf.int64, [None, 1])\n",
    "\n",
    "ys_one_hot = tf.one_hot(ys, 10)\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "with tf.variable_scope('center'):\n",
    "    centers = tf.get_variable('centers', [10, 1024], dtype=tf.float32,\\\n",
    "                          initializer=tf.constant_initializer(0), trainable=False)\n",
    "#------CNN1-------#\n",
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])\n",
    "\n",
    "x_image = tf.reshape(xs, [-1,28,28,1])\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "#-------CNN2-------#\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "#-------DNN------#\n",
    "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "s_fc1 = scale_variable([1024])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "\n",
    "h_fc1 = DNN_BN(h_pool2_flat, W_fc1, b_fc1, s_fc1, tf.nn.relu)\n",
    "\n",
    "center_loss = get_center_loss(h_fc1, ys)\n",
    "\n",
    "update_centers = update_centers(h_fc1, ys, 0.5)\n",
    "\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "#-------DNN2-----#\n",
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "\n",
    "#----------------#\n",
    "softmax_loss = tf.nn.softmax_cross_entropy_with_logits(labels=ys_one_hot, logits=y_conv)\n",
    "\n",
    "loss = tf.reduce_mean(softmax_loss + 1.0 * center_loss)\n",
    "\n",
    "train_op = tf.train.AdamOptimizer(1e-4).minimize(loss)\n",
    "\n",
    "result = tf.argmax(y_conv,1)\n",
    "\n",
    "ground_truth = tf.reshape(ys, [-1])\n",
    "\n",
    "correct_prediction = tf.equal(result, ground_truth)\n",
    "\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for i in range(60):\n",
    "        print 'LOSS, Softmax_loss, Center_loss', sess.run([loss, softmax_loss, center_loss], feed_dict = {xs: x_train, ys: y_train.values, keep_prob:1.0})\n",
    "        print 'ACC@TRAIN:', sess.run(accuracy, feed_dict = {xs: x_train, ys: y_train.values, keep_prob:1.0})\n",
    "        print 'ACC@DEV:', sess.run(accuracy, feed_dict = {xs: x_dev, ys: y_dev.values, keep_prob:1.0})\n",
    "        j = 0\n",
    "        while j < 30000:       \n",
    "            _, cen = sess.run([train_op, update_centers], feed_dict = {xs: x_train[j:j+1000], ys: y_train[j:j+1000].values, keep_prob:1.0})\n",
    "            \n",
    "            j += 1000  \n",
    "    pd.DataFrame({\"ImageId\": range(1, len(x_test) + 1), \"Label\": sess.run(result, feed_dict = {xs: x_test, keep_prob:1.0})}).to_csv('MNIST_data/BN_CENTER_LOSS.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
